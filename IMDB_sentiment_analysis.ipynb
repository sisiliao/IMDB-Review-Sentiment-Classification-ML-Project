{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB sentiment analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "e4J918jyhpA0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Enviromental Setup and Library import"
      ]
    },
    {
      "metadata": {
        "id": "K4L2c2cI4qRA",
        "colab_type": "code",
        "outputId": "9a0aec87-a34e-419d-bf98-ce335c08abe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import csv\n",
        "import time\n",
        "import nltk\n",
        "import math\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import wordnet\n",
        "from scipy.stats import uniform\n",
        "from scipy.stats import randint\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "from sklearn import datasets\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "!unzip -qq gdrive/My\\ Drive/dataset.zip\n",
        "stop = stopwords.words('english')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ieGrf-3Fhx_-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Read data from .txt files and preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "RkkVs2Ons8xi",
        "colab_type": "code",
        "outputId": "b3ed3213-90a1-4a76-919d-deab562a9711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "cell_type": "code",
      "source": [
        "def read_data(tp):\n",
        "    print('Reading %s data to Pandas Dataframe...' %(tp))\n",
        "    path = 'dataset/' + tp + '/'\n",
        "    labels = {'pos':1, 'neg':0}\n",
        "  \n",
        "    df = pd.DataFrame()\n",
        "    start = time.time()\n",
        "    if tp == 'train':\n",
        "        for p in labels.keys():\n",
        "            list_of_files = os.listdir(path + p + '/')\n",
        "            for file in list_of_files:\n",
        "                f = open(path + p + '/' + file, 'r')\n",
        "                txt = f.read()\n",
        "                df = df.append([[txt, labels[p]]], ignore_index = True)\n",
        "                f.close()\n",
        "    \n",
        "    else:\n",
        "        list_of_files = os.listdir(path)\n",
        "        for file in list_of_files:\n",
        "            f = open(path + file, 'r')\n",
        "            txt = f.read()\n",
        "            id = int(re.sub('.txt', '', file))\n",
        "            df = df.append([[txt, id+100000]], ignore_index = True)\n",
        "            f.close()\n",
        "      \n",
        "    df.columns = ['text', 'sentiment']\n",
        "    print('Done.')\n",
        "    end = time.time()\n",
        "    print('Time elapsed on reading is', end - start,'\\n')\n",
        "    return df\n",
        "np.random.seed(88)   \n",
        "tr_raw = read_data('train')\n",
        "te_raw = read_data('test')\n",
        "df_raw = pd.concat([tr_raw, te_raw], axis = 0)\n",
        "df_raw.describe()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading train data to Pandas Dataframe...\n",
            "Done.\n",
            "Time elapsed on reading is 41.44776391983032 \n",
            "\n",
            "Reading test data to Pandas Dataframe...\n",
            "Done.\n",
            "Time elapsed on reading is 41.90396785736084 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>56250.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>56481.073992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>50000.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>112499.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>124999.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           sentiment\n",
              "count   50000.000000\n",
              "mean    56250.000000\n",
              "std     56481.073992\n",
              "min         0.000000\n",
              "25%         0.750000\n",
              "50%     50000.500000\n",
              "75%    112499.250000\n",
              "max    124999.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "kQ9GbQs5dziM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#nltk.download('wordnet')\n",
        "def preprocess(text): \n",
        "    text = text.lower().split()\n",
        "#     stops = set(stopwords.words(\"english\"))\n",
        "#     text = [w for w in text if not w in stops and len(w) >= 3]\n",
        "    text = \" \".join(text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"^https?:\\/\\/.*[\\r\\n]*\",\"\", text)\n",
        "    text = text.split()\n",
        "    lemma = nltk.wordnet.WordNetLemmatizer()\n",
        "    stemmed_words = [lemma.lemmatize(word) for word in text]\n",
        "    text = \" \".join(stemmed_words)\n",
        "    return text\n",
        "df = df_raw.copy()\n",
        "df['text'] = df['text'].map(lambda x: preprocess(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0SqfottDFN4z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset Split"
      ]
    },
    {
      "metadata": {
        "id": "t9fZsdPuAtkf",
        "colab_type": "code",
        "outputId": "3a99bb6a-a902-413f-a998-76e668a0c925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.loc[df['sentiment']<2]['text'], df.loc[df['sentiment']<2]['sentiment'], train_size=0.75, test_size=0.25)\n",
        "X_train_total = df.loc[df['sentiment']<2]['text'].copy()\n",
        "y_train_total = df.loc[df['sentiment']<2]['sentiment'].copy()\n",
        "X_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19692    dave is going through a divorce and his mind w...\n",
              "11457    a wonderful free flowing often lyrical film th...\n",
              "13050    never even knew this movie existed until i fou...\n",
              "16393    watching that lady in ermine i wa wondering wh...\n",
              "21348    2 star for kay francis - - she wonderful ! and...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "OCbKR4V2FZJy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction and Model Pipeline"
      ]
    },
    {
      "metadata": {
        "id": "WEhkB5AYMjrY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def csv_exp(result, name):\n",
        "  csv = result.to_csv(index=False)\n",
        "  f = open(name+'.csv','w')\n",
        "  f.write(csv)\n",
        "  f.close()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnPmXkRXt7SQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(arr1, arr2):\n",
        "  return 1 - sum(abs(arr1 - arr2))/len(arr1)\n",
        "seed = 88"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L6joahr9-cLD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cv_tabular(result):\n",
        "  dic = {}\n",
        "  for x in result['params'][0]:\n",
        "    dic[x] = []\n",
        "  for x in result['params']:\n",
        "    for key in dic.keys():\n",
        "      dic[key].append(x[key])\n",
        "  cv_df = pd.DataFrame(data = dic)\n",
        "  cv_df['mean_test_score'] = result['mean_test_score']\n",
        "  cv_df['std_test_score'] = result['std_test_score']\n",
        "  cv_df['mean_fit_time'] = result['mean_fit_time']\n",
        "  cv_df = cv_df.sort_values(by = 'mean_test_score')\n",
        "  return cv_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PgasK82IaG_1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Estimator"
      ]
    },
    {
      "metadata": {
        "id": "9RkLvBXA1SPT",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logreg = Pipeline([\n",
        "    ('vect', CountVectorizer(binary = True)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('norm', Normalizer()),\n",
        "    ('clf', LogisticRegression(C=10)),\n",
        "])\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrY5-uVnTXRr",
        "colab_type": "code",
        "outputId": "0ba7e234-55ca-432a-8c5c-f332cbea0e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1508
        }
      },
      "cell_type": "code",
      "source": [
        "seed = 130\n",
        "params_log = {\"vect__ngram_range\": [(1,1),(2,2),(3,3)],\n",
        "              \"vect__binary\":[True, False],\n",
        "              \"vect__max_features\":[None, 50000, 100000],\n",
        "              \"clf__penalty\": [\"l2\", \"l1\"]}\n",
        "logreg_cv = GridSearchCV(logreg, param_grid = params_log, cv=2, verbose = 10, n_jobs = -1)\n",
        "logreg_cv.fit(X_train, y_train)\n",
        "y_pred = logreg_cv.predict(X_test)\n",
        "print('My best accuracy is', accuracy(y_test, y_pred))\n",
        "print('Best model is', logreg_cv.best_params_)\n",
        "cv_tabular(logreg_cv.cv_results_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   13.0s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   39.2s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.5min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  8.8min\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 11.0min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 12.9min\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 13.8min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "My best accuracy is 0.89232\n",
            "Best model is {'clf__penalty': 'l2', 'vect__binary': False, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clf__penalty</th>\n",
              "      <th>vect__binary</th>\n",
              "      <th>vect__max_features</th>\n",
              "      <th>vect__ngram_range</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>mean_fit_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>l1</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.774080</td>\n",
              "      <td>0.001363</td>\n",
              "      <td>28.247177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>l1</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.774827</td>\n",
              "      <td>0.001411</td>\n",
              "      <td>28.160753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>l1</td>\n",
              "      <td>False</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.775520</td>\n",
              "      <td>0.001523</td>\n",
              "      <td>18.211167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>l1</td>\n",
              "      <td>False</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.775733</td>\n",
              "      <td>0.002269</td>\n",
              "      <td>18.462948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>l1</td>\n",
              "      <td>True</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.775787</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>18.281320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>l1</td>\n",
              "      <td>True</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.776587</td>\n",
              "      <td>0.001523</td>\n",
              "      <td>18.369485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.819467</td>\n",
              "      <td>0.001353</td>\n",
              "      <td>18.052719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.820107</td>\n",
              "      <td>0.003166</td>\n",
              "      <td>18.169940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.826133</td>\n",
              "      <td>0.002792</td>\n",
              "      <td>18.140384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.827040</td>\n",
              "      <td>0.002952</td>\n",
              "      <td>18.426915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>l1</td>\n",
              "      <td>False</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.829067</td>\n",
              "      <td>0.003912</td>\n",
              "      <td>11.503198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>l1</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.829920</td>\n",
              "      <td>0.003911</td>\n",
              "      <td>14.834449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>l1</td>\n",
              "      <td>False</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.830027</td>\n",
              "      <td>0.003911</td>\n",
              "      <td>10.930691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.830720</td>\n",
              "      <td>0.002791</td>\n",
              "      <td>23.474258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>l1</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.831200</td>\n",
              "      <td>0.003911</td>\n",
              "      <td>15.315727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.831680</td>\n",
              "      <td>0.004285</td>\n",
              "      <td>23.232582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>l1</td>\n",
              "      <td>True</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.832587</td>\n",
              "      <td>0.003591</td>\n",
              "      <td>11.605850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>l1</td>\n",
              "      <td>True</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.832693</td>\n",
              "      <td>0.003591</td>\n",
              "      <td>11.565894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>l1</td>\n",
              "      <td>True</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.857920</td>\n",
              "      <td>0.001828</td>\n",
              "      <td>7.409790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>l1</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.857973</td>\n",
              "      <td>0.001775</td>\n",
              "      <td>7.400644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>l1</td>\n",
              "      <td>True</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.857973</td>\n",
              "      <td>0.001775</td>\n",
              "      <td>7.135290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>l1</td>\n",
              "      <td>False</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.861707</td>\n",
              "      <td>0.002948</td>\n",
              "      <td>5.230722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>l1</td>\n",
              "      <td>False</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.861707</td>\n",
              "      <td>0.002948</td>\n",
              "      <td>5.240810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>l1</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.861707</td>\n",
              "      <td>0.002948</td>\n",
              "      <td>4.913795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.868427</td>\n",
              "      <td>0.002521</td>\n",
              "      <td>11.536016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.869013</td>\n",
              "      <td>0.003427</td>\n",
              "      <td>11.391210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.869387</td>\n",
              "      <td>0.001987</td>\n",
              "      <td>14.497823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.870880</td>\n",
              "      <td>0.003054</td>\n",
              "      <td>12.272934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.872907</td>\n",
              "      <td>0.004440</td>\n",
              "      <td>14.174666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.873387</td>\n",
              "      <td>0.004920</td>\n",
              "      <td>11.891348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.880320</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>4.373055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.880320</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>4.266453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.880320</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>4.278253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.883520</td>\n",
              "      <td>0.001719</td>\n",
              "      <td>4.990930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.883520</td>\n",
              "      <td>0.001719</td>\n",
              "      <td>4.917766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.883520</td>\n",
              "      <td>0.001719</td>\n",
              "      <td>4.749144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   clf__penalty  vect__binary  vect__max_features vect__ngram_range  \\\n",
              "20           l1          True                 NaN            (3, 3)   \n",
              "29           l1         False                 NaN            (3, 3)   \n",
              "32           l1         False             50000.0            (3, 3)   \n",
              "35           l1         False            100000.0            (3, 3)   \n",
              "26           l1          True            100000.0            (3, 3)   \n",
              "23           l1          True             50000.0            (3, 3)   \n",
              "5            l2          True             50000.0            (3, 3)   \n",
              "14           l2         False             50000.0            (3, 3)   \n",
              "8            l2          True            100000.0            (3, 3)   \n",
              "17           l2         False            100000.0            (3, 3)   \n",
              "34           l1         False            100000.0            (2, 2)   \n",
              "28           l1         False                 NaN            (2, 2)   \n",
              "31           l1         False             50000.0            (2, 2)   \n",
              "11           l2         False                 NaN            (3, 3)   \n",
              "19           l1          True                 NaN            (2, 2)   \n",
              "2            l2          True                 NaN            (3, 3)   \n",
              "25           l1          True            100000.0            (2, 2)   \n",
              "22           l1          True             50000.0            (2, 2)   \n",
              "21           l1          True             50000.0            (1, 1)   \n",
              "18           l1          True                 NaN            (1, 1)   \n",
              "24           l1          True            100000.0            (1, 1)   \n",
              "33           l1         False            100000.0            (1, 1)   \n",
              "30           l1         False             50000.0            (1, 1)   \n",
              "27           l1         False                 NaN            (1, 1)   \n",
              "13           l2         False             50000.0            (2, 2)   \n",
              "4            l2          True             50000.0            (2, 2)   \n",
              "10           l2         False                 NaN            (2, 2)   \n",
              "16           l2         False            100000.0            (2, 2)   \n",
              "1            l2          True                 NaN            (2, 2)   \n",
              "7            l2          True            100000.0            (2, 2)   \n",
              "6            l2          True            100000.0            (1, 1)   \n",
              "3            l2          True             50000.0            (1, 1)   \n",
              "0            l2          True                 NaN            (1, 1)   \n",
              "9            l2         False                 NaN            (1, 1)   \n",
              "15           l2         False            100000.0            (1, 1)   \n",
              "12           l2         False             50000.0            (1, 1)   \n",
              "\n",
              "    mean_test_score  std_test_score  mean_fit_time  \n",
              "20         0.774080        0.001363      28.247177  \n",
              "29         0.774827        0.001411      28.160753  \n",
              "32         0.775520        0.001523      18.211167  \n",
              "35         0.775733        0.002269      18.462948  \n",
              "26         0.775787        0.000723      18.281320  \n",
              "23         0.776587        0.001523      18.369485  \n",
              "5          0.819467        0.001353      18.052719  \n",
              "14         0.820107        0.003166      18.169940  \n",
              "8          0.826133        0.002792      18.140384  \n",
              "17         0.827040        0.002952      18.426915  \n",
              "34         0.829067        0.003912      11.503198  \n",
              "28         0.829920        0.003911      14.834449  \n",
              "31         0.830027        0.003911      10.930691  \n",
              "11         0.830720        0.002791      23.474258  \n",
              "19         0.831200        0.003911      15.315727  \n",
              "2          0.831680        0.004285      23.232582  \n",
              "25         0.832587        0.003591      11.605850  \n",
              "22         0.832693        0.003591      11.565894  \n",
              "21         0.857920        0.001828       7.409790  \n",
              "18         0.857973        0.001775       7.400644  \n",
              "24         0.857973        0.001775       7.135290  \n",
              "33         0.861707        0.002948       5.230722  \n",
              "30         0.861707        0.002948       5.240810  \n",
              "27         0.861707        0.002948       4.913795  \n",
              "13         0.868427        0.002521      11.536016  \n",
              "4          0.869013        0.003427      11.391210  \n",
              "10         0.869387        0.001987      14.497823  \n",
              "16         0.870880        0.003054      12.272934  \n",
              "1          0.872907        0.004440      14.174666  \n",
              "7          0.873387        0.004920      11.891348  \n",
              "6          0.880320        0.000439       4.373055  \n",
              "3          0.880320        0.000439       4.266453  \n",
              "0          0.880320        0.000439       4.278253  \n",
              "9          0.883520        0.001719       4.990930  \n",
              "15         0.883520        0.001719       4.917766  \n",
              "12         0.883520        0.001719       4.749144  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "37tgCMijMUA2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logreg_result = cv_tabular(logreg_cv.cv_results_)\n",
        "csv_exp(logreg_result, 'Logreg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tNYjJCRPTd_A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Decision Tree Estimator"
      ]
    },
    {
      "metadata": {
        "id": "tTGFb8NZTu1h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dec_tree = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('norm', Normalizer()),\n",
        "    ('clf-tree', tree.DecisionTreeClassifier())\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N1iEank5ro8G",
        "colab_type": "code",
        "outputId": "4c2bdd68-4c70-4846-c0d3-b9e3c26c888d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "params_dt = {\"vect__ngram_range\": [(1,1),(2,2)],\n",
        "             \"vect__max_features\":[None, 10000, 50000],\n",
        "             \"clf-tree__max_depth\": [None, 500, 5000]}\n",
        "dec_tree_cv = GridSearchCV(dec_tree, param_grid = params_dt, cv=2, verbose = 10, n_jobs = -1)\n",
        "dec_tree_cv.fit(X_train, y_train)\n",
        "y_pred = dec_tree_cv.predict(X_test)\n",
        "print('My accuracy is', accuracy(y_test, y_pred))\n",
        "print('Best model is', dec_tree_cv.best_params_)\n",
        "dt_result = cv_tabular(dec_tree_cv.cv_results_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   26.5s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  2.2min\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 10.7min\n",
            "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 12.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "My accuracy is 0.69552\n",
            "Best model is {'clf-tree__max_depth': None, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XlX7LTuVTKVh",
        "colab_type": "code",
        "outputId": "7a8d8de3-e8fb-462d-b80a-0643b6494127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "cell_type": "code",
      "source": [
        "csv_exp(dt_result, 'dectree')\n",
        "cv_tabular(dec_tree_cv.cv_results_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clf-tree__max_depth</th>\n",
              "      <th>vect__max_features</th>\n",
              "      <th>vect__ngram_range</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>mean_fit_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.642187</td>\n",
              "      <td>0.004252</td>\n",
              "      <td>91.414668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.647573</td>\n",
              "      <td>0.003878</td>\n",
              "      <td>92.497577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>500.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.648533</td>\n",
              "      <td>0.004197</td>\n",
              "      <td>91.646705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>500.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.652533</td>\n",
              "      <td>0.004677</td>\n",
              "      <td>22.837389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5000.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.654293</td>\n",
              "      <td>0.006437</td>\n",
              "      <td>22.872181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.654453</td>\n",
              "      <td>0.002330</td>\n",
              "      <td>22.857502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5000.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.656107</td>\n",
              "      <td>0.005263</td>\n",
              "      <td>34.245579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>500.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.656853</td>\n",
              "      <td>0.005583</td>\n",
              "      <td>33.407316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.657120</td>\n",
              "      <td>0.008623</td>\n",
              "      <td>33.167261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5000.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.683040</td>\n",
              "      <td>0.000834</td>\n",
              "      <td>18.165090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>500.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.684427</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>18.359511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>500.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.684640</td>\n",
              "      <td>0.002114</td>\n",
              "      <td>18.320746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.685973</td>\n",
              "      <td>0.002380</td>\n",
              "      <td>18.372676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.686400</td>\n",
              "      <td>0.000287</td>\n",
              "      <td>18.357898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5000.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.686560</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>15.659238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.688320</td>\n",
              "      <td>0.002273</td>\n",
              "      <td>18.241943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>500.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.689280</td>\n",
              "      <td>0.003766</td>\n",
              "      <td>15.361407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.690133</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>15.594618</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    clf-tree__max_depth  vect__max_features vect__ngram_range  \\\n",
              "1                   NaN                 NaN            (2, 2)   \n",
              "13               5000.0                 NaN            (2, 2)   \n",
              "7                 500.0                 NaN            (2, 2)   \n",
              "9                 500.0             10000.0            (2, 2)   \n",
              "15               5000.0             10000.0            (2, 2)   \n",
              "3                   NaN             10000.0            (2, 2)   \n",
              "17               5000.0             50000.0            (2, 2)   \n",
              "11                500.0             50000.0            (2, 2)   \n",
              "5                   NaN             50000.0            (2, 2)   \n",
              "16               5000.0             50000.0            (1, 1)   \n",
              "10                500.0             50000.0            (1, 1)   \n",
              "6                 500.0                 NaN            (1, 1)   \n",
              "12               5000.0                 NaN            (1, 1)   \n",
              "0                   NaN                 NaN            (1, 1)   \n",
              "14               5000.0             10000.0            (1, 1)   \n",
              "4                   NaN             50000.0            (1, 1)   \n",
              "8                 500.0             10000.0            (1, 1)   \n",
              "2                   NaN             10000.0            (1, 1)   \n",
              "\n",
              "    mean_test_score  std_test_score  mean_fit_time  \n",
              "1          0.642187        0.004252      91.414668  \n",
              "13         0.647573        0.003878      92.497577  \n",
              "7          0.648533        0.004197      91.646705  \n",
              "9          0.652533        0.004677      22.837389  \n",
              "15         0.654293        0.006437      22.872181  \n",
              "3          0.654453        0.002330      22.857502  \n",
              "17         0.656107        0.005263      34.245579  \n",
              "11         0.656853        0.005583      33.407316  \n",
              "5          0.657120        0.008623      33.167261  \n",
              "16         0.683040        0.000834      18.165090  \n",
              "10         0.684427        0.001047      18.359511  \n",
              "6          0.684640        0.002114      18.320746  \n",
              "12         0.685973        0.002380      18.372676  \n",
              "0          0.686400        0.000287      18.357898  \n",
              "14         0.686560        0.001087      15.659238  \n",
              "4          0.688320        0.002273      18.241943  \n",
              "8          0.689280        0.003766      15.361407  \n",
              "2          0.690133        0.000033      15.594618  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "7pTlUJ0NKh9h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SVM Estimator"
      ]
    },
    {
      "metadata": {
        "id": "eIwIe4c6KlCb",
        "colab_type": "code",
        "outputId": "112e3354-2b22-4178-ca9e-718c9bb7026a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1051
        }
      },
      "cell_type": "code",
      "source": [
        "lsvm = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('norm', Normalizer()),\n",
        "    ('clf', LinearSVC(random_state = 0, tol = 1e-7)),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "params_svm = {\"vect__ngram_range\": [(1,1), (1,2),(2,2),(3,3)],\n",
        "              \"vect__binary\":[True, False],\n",
        "              \"vect__max_features\":[None, 50000, 100000],\n",
        "              \"clf__penalty\": [\"l2\"]}\n",
        "lsvm_cv = GridSearchCV(lsvm, param_grid = params_svm, cv=2, verbose = 10, n_jobs = -1)\n",
        "lsvm_cv.fit(X_train, y_train)\n",
        "y_pred = lsvm_cv.predict(X_test)\n",
        "print('My best accuracy is', accuracy(y_test, y_pred))\n",
        "print('Best model is', lsvm_cv.best_params_)\n",
        "cv_tabular(lsvm_cv.cv_results_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   10.6s\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   44.9s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  5.7min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  9.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "My best accuracy is 0.90912\n",
            "Best model is {'clf__penalty': 'l2', 'vect__binary': True, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clf__penalty</th>\n",
              "      <th>vect__binary</th>\n",
              "      <th>vect__max_features</th>\n",
              "      <th>vect__ngram_range</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>mean_fit_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.816427</td>\n",
              "      <td>0.001726</td>\n",
              "      <td>18.104129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.818827</td>\n",
              "      <td>0.003059</td>\n",
              "      <td>18.087718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.825707</td>\n",
              "      <td>0.003219</td>\n",
              "      <td>18.290069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.825813</td>\n",
              "      <td>0.003112</td>\n",
              "      <td>18.186085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.832213</td>\n",
              "      <td>0.002791</td>\n",
              "      <td>23.316297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(3, 3)</td>\n",
              "      <td>0.834027</td>\n",
              "      <td>0.003858</td>\n",
              "      <td>23.607040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.866613</td>\n",
              "      <td>0.003801</td>\n",
              "      <td>11.022082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.867413</td>\n",
              "      <td>0.003961</td>\n",
              "      <td>10.914057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.870773</td>\n",
              "      <td>0.004440</td>\n",
              "      <td>11.528902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.872320</td>\n",
              "      <td>0.002147</td>\n",
              "      <td>13.618436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.872427</td>\n",
              "      <td>0.005347</td>\n",
              "      <td>11.267182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(2, 2)</td>\n",
              "      <td>0.876267</td>\n",
              "      <td>0.004707</td>\n",
              "      <td>13.462282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.878933</td>\n",
              "      <td>0.000226</td>\n",
              "      <td>3.843432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.878933</td>\n",
              "      <td>0.000226</td>\n",
              "      <td>3.909051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.878933</td>\n",
              "      <td>0.000226</td>\n",
              "      <td>3.810569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.882827</td>\n",
              "      <td>0.001559</td>\n",
              "      <td>3.907902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.882827</td>\n",
              "      <td>0.001559</td>\n",
              "      <td>3.933064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(1, 1)</td>\n",
              "      <td>0.882827</td>\n",
              "      <td>0.001559</td>\n",
              "      <td>3.828527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.891413</td>\n",
              "      <td>0.003638</td>\n",
              "      <td>14.367291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.891893</td>\n",
              "      <td>0.002945</td>\n",
              "      <td>17.709607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.892107</td>\n",
              "      <td>0.003372</td>\n",
              "      <td>14.527251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>l2</td>\n",
              "      <td>False</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.892800</td>\n",
              "      <td>0.003105</td>\n",
              "      <td>14.897370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.894827</td>\n",
              "      <td>0.004171</td>\n",
              "      <td>14.969651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>l2</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>0.895840</td>\n",
              "      <td>0.004011</td>\n",
              "      <td>17.433294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   clf__penalty  vect__binary  vect__max_features vect__ngram_range  \\\n",
              "7            l2          True             50000.0            (3, 3)   \n",
              "19           l2         False             50000.0            (3, 3)   \n",
              "11           l2          True            100000.0            (3, 3)   \n",
              "23           l2         False            100000.0            (3, 3)   \n",
              "15           l2         False                 NaN            (3, 3)   \n",
              "3            l2          True                 NaN            (3, 3)   \n",
              "18           l2         False             50000.0            (2, 2)   \n",
              "6            l2          True             50000.0            (2, 2)   \n",
              "22           l2         False            100000.0            (2, 2)   \n",
              "14           l2         False                 NaN            (2, 2)   \n",
              "10           l2          True            100000.0            (2, 2)   \n",
              "2            l2          True                 NaN            (2, 2)   \n",
              "4            l2          True             50000.0            (1, 1)   \n",
              "0            l2          True                 NaN            (1, 1)   \n",
              "8            l2          True            100000.0            (1, 1)   \n",
              "16           l2         False             50000.0            (1, 1)   \n",
              "20           l2         False            100000.0            (1, 1)   \n",
              "12           l2         False                 NaN            (1, 1)   \n",
              "17           l2         False             50000.0            (1, 2)   \n",
              "13           l2         False                 NaN            (1, 2)   \n",
              "5            l2          True             50000.0            (1, 2)   \n",
              "21           l2         False            100000.0            (1, 2)   \n",
              "9            l2          True            100000.0            (1, 2)   \n",
              "1            l2          True                 NaN            (1, 2)   \n",
              "\n",
              "    mean_test_score  std_test_score  mean_fit_time  \n",
              "7          0.816427        0.001726      18.104129  \n",
              "19         0.818827        0.003059      18.087718  \n",
              "11         0.825707        0.003219      18.290069  \n",
              "23         0.825813        0.003112      18.186085  \n",
              "15         0.832213        0.002791      23.316297  \n",
              "3          0.834027        0.003858      23.607040  \n",
              "18         0.866613        0.003801      11.022082  \n",
              "6          0.867413        0.003961      10.914057  \n",
              "22         0.870773        0.004440      11.528902  \n",
              "14         0.872320        0.002147      13.618436  \n",
              "10         0.872427        0.005347      11.267182  \n",
              "2          0.876267        0.004707      13.462282  \n",
              "4          0.878933        0.000226       3.843432  \n",
              "0          0.878933        0.000226       3.909051  \n",
              "8          0.878933        0.000226       3.810569  \n",
              "16         0.882827        0.001559       3.907902  \n",
              "20         0.882827        0.001559       3.933064  \n",
              "12         0.882827        0.001559       3.828527  \n",
              "17         0.891413        0.003638      14.367291  \n",
              "13         0.891893        0.002945      17.709607  \n",
              "5          0.892107        0.003372      14.527251  \n",
              "21         0.892800        0.003105      14.897370  \n",
              "9          0.894827        0.004171      14.969651  \n",
              "1          0.895840        0.004011      17.433294  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "22EnPJSTKedC",
        "colab_type": "code",
        "outputId": "3583a3b3-b22b-4a61-d173-9b11066c9cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3454
        }
      },
      "cell_type": "code",
      "source": [
        "lsvm_result = cv_tabular(lsvm_cv.cv_results_)\n",
        "csv_exp(lsvm_result, 'SVM')\n",
        "lsvm_cv.cv_results_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([ 3.90905058, 17.43329358, 13.4622823 , 23.60703969,  3.84343219,\n",
              "        14.52725112, 10.91405678, 18.1041286 ,  3.81056917, 14.96965086,\n",
              "        11.26718199, 18.29006922,  3.82852721, 17.70960701, 13.6184355 ,\n",
              "        23.31629741,  3.90790236, 14.36729133, 11.02208221, 18.08771765,\n",
              "         3.93306446, 14.89736974, 11.52890229, 18.1860851 ]),\n",
              " 'mean_score_time': array([3.25155175, 8.0533061 , 5.52807069, 5.21393907, 3.22354603,\n",
              "        7.02148521, 4.82232594, 4.50837517, 3.21385038, 7.20965314,\n",
              "        5.01445651, 4.62814975, 3.21944761, 8.03112328, 5.59926641,\n",
              "        5.26215601, 3.24873793, 7.05690515, 4.87247157, 4.56963181,\n",
              "        3.24611127, 7.28990579, 4.99291503, 4.64363801]),\n",
              " 'mean_test_score': array([0.87893333, 0.89584   , 0.87626667, 0.83402667, 0.87893333,\n",
              "        0.89210667, 0.86741333, 0.81642667, 0.87893333, 0.89482667,\n",
              "        0.87242667, 0.82570667, 0.88282667, 0.89189333, 0.87232   ,\n",
              "        0.83221333, 0.88282667, 0.89141333, 0.86661333, 0.81882667,\n",
              "        0.88282667, 0.8928    , 0.87077333, 0.82581333]),\n",
              " 'mean_train_score': array([0.99770663, 1.        , 1.        , 1.        , 0.99770663,\n",
              "        0.99989333, 0.99994667, 0.99994666, 0.99770663, 0.99994667,\n",
              "        0.99994667, 0.99994666, 0.99578658, 0.99989333, 1.        ,\n",
              "        1.        , 0.99578658, 0.99978667, 0.99989334, 0.99994666,\n",
              "        0.99578658, 0.99983999, 0.99994667, 0.99994666]),\n",
              " 'param_clf__penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
              "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_vect__binary': masked_array(data=[True, True, True, True, True, True, True, True, True,\n",
              "                    True, True, True, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_vect__max_features': masked_array(data=[None, None, None, None, 50000, 50000, 50000, 50000,\n",
              "                    100000, 100000, 100000, 100000, None, None, None, None,\n",
              "                    50000, 50000, 50000, 50000, 100000, 100000, 100000,\n",
              "                    100000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_vect__ngram_range': masked_array(data=[(1, 1), (1, 2), (2, 2), (3, 3), (1, 1), (1, 2), (2, 2),\n",
              "                    (3, 3), (1, 1), (1, 2), (2, 2), (3, 3), (1, 1), (1, 2),\n",
              "                    (2, 2), (3, 3), (1, 1), (1, 2), (2, 2), (3, 3), (1, 1),\n",
              "                    (1, 2), (2, 2), (3, 3)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': None,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': None,\n",
              "   'vect__ngram_range': (1, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': None,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': None,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': 50000,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': 50000,\n",
              "   'vect__ngram_range': (1, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': 50000,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': 50000,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': 100000,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': 100000,\n",
              "   'vect__ngram_range': (1, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': 100000,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': True,\n",
              "   'vect__max_features': 100000,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': None,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': None,\n",
              "   'vect__ngram_range': (1, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': None,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': None,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': 50000,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': 50000,\n",
              "   'vect__ngram_range': (1, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': 50000,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': 50000,\n",
              "   'vect__ngram_range': (3, 3)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': 100000,\n",
              "   'vect__ngram_range': (1, 1)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': 100000,\n",
              "   'vect__ngram_range': (1, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': 100000,\n",
              "   'vect__ngram_range': (2, 2)},\n",
              "  {'clf__penalty': 'l2',\n",
              "   'vect__binary': False,\n",
              "   'vect__max_features': 100000,\n",
              "   'vect__ngram_range': (3, 3)}],\n",
              " 'rank_test_score': array([10,  1, 13, 19, 10,  4, 17, 24, 10,  2, 14, 22,  7,  5, 15, 20,  7,\n",
              "         6, 18, 23,  7,  3, 16, 21], dtype=int32),\n",
              " 'split0_test_score': array([0.87915956, 0.89985068, 0.8809727 , 0.83788396, 0.87915956,\n",
              "        0.89547782, 0.87137372, 0.81815273, 0.87915956, 0.89899744,\n",
              "        0.87777304, 0.82892491, 0.88438567, 0.89483788, 0.87446672,\n",
              "        0.83500427, 0.88438567, 0.89505119, 0.87041382, 0.82188567,\n",
              "        0.88438567, 0.89590444, 0.87521331, 0.82892491]),\n",
              " 'split0_train_score': array([0.99733305, 1.        , 1.        , 1.        , 0.99733305,\n",
              "        0.99989332, 1.        , 0.99989332, 0.99733305, 1.        ,\n",
              "        1.        , 0.99989332, 0.99498613, 0.99989332, 1.        ,\n",
              "        1.        , 0.99498613, 0.99978664, 1.        , 0.99989332,\n",
              "        0.99498613, 0.99978664, 1.        , 0.99989332]),\n",
              " 'split1_test_score': array([0.87870706, 0.89182846, 0.87155963, 0.83016855, 0.87870706,\n",
              "        0.8887348 , 0.8634521 , 0.81470023, 0.87870706, 0.890655  ,\n",
              "        0.86707916, 0.82248773, 0.88126734, 0.88894815, 0.87017282,\n",
              "        0.8294218 , 0.88126734, 0.8877747 , 0.86281203, 0.81576702,\n",
              "        0.88126734, 0.8896949 , 0.86633241, 0.82270109]),\n",
              " 'split1_train_score': array([0.9980802 , 1.        , 1.        , 1.        , 0.9980802 ,\n",
              "        0.99989334, 0.99989334, 1.        , 0.9980802 , 0.99989334,\n",
              "        0.99989334, 1.        , 0.99658703, 0.99989334, 1.        ,\n",
              "        1.        , 0.99658703, 0.99978669, 0.99978669, 1.        ,\n",
              "        0.99658703, 0.99989334, 0.99989334, 1.        ]),\n",
              " 'std_fit_time': array([0.00462997, 0.08274293, 0.04985678, 0.59049797, 0.00449514,\n",
              "        0.26228774, 0.05849624, 0.24722576, 0.00883138, 0.06916726,\n",
              "        0.02911913, 0.00743353, 0.02469206, 0.31372988, 0.25691497,\n",
              "        0.10247624, 0.10351145, 0.29109657, 0.02925503, 0.03531849,\n",
              "        0.05491972, 0.01632273, 0.07664609, 0.07890356]),\n",
              " 'std_score_time': array([0.00850928, 0.11313868, 0.0369184 , 0.03271902, 0.00342727,\n",
              "        0.10968196, 0.03069758, 0.00528073, 0.00822484, 0.03880191,\n",
              "        0.05147052, 0.03274751, 0.00908852, 0.00854957, 0.01431191,\n",
              "        0.00956917, 0.00472534, 0.00483024, 0.01320171, 0.03378248,\n",
              "        0.00853765, 0.03741956, 0.05513561, 0.04823196]),\n",
              " 'std_test_score': array([0.00022625, 0.00401111, 0.00470653, 0.0038577 , 0.00022625,\n",
              "        0.00337151, 0.00396081, 0.00172625, 0.00022625, 0.00417122,\n",
              "        0.00534694, 0.00321859, 0.00155917, 0.00294486, 0.00214695,\n",
              "        0.00279123, 0.00155917, 0.00363825, 0.00380089, 0.00305933,\n",
              "        0.00155917, 0.00310477, 0.00444045, 0.00311191]),\n",
              " 'std_train_score': array([3.73577960e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "        3.73577960e-04, 1.13777779e-08, 5.33276451e-05, 5.33390228e-05,\n",
              "        3.73577960e-04, 5.33276451e-05, 5.33276451e-05, 5.33390228e-05,\n",
              "        8.00449431e-04, 1.13777779e-08, 0.00000000e+00, 0.00000000e+00,\n",
              "        8.00449431e-04, 2.27555558e-08, 1.06655290e-04, 5.33390228e-05,\n",
              "        8.00449431e-04, 5.33504006e-05, 5.33276451e-05, 5.33390228e-05])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "rko6jcKENq6X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "metadata": {
        "id": "lS2L0OqvQS8f",
        "colab_type": "code",
        "outputId": "3bee8c4c-ec4e-4fce-de6a-406c539f866c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class NaiveBayes:\n",
        "  def __init__(self, X_train, y_train):\n",
        "    self.X_train = X_train\n",
        "    self.y_train = y_train\n",
        "    self.count_vect = None\n",
        "    self.X_train_counts = None\n",
        "    \n",
        "    #prior\n",
        "    self.pos_count = -1\n",
        "    self.neg_count = -1\n",
        "    self.doc_count = -1\n",
        "    self.prior_log_pos = -1\n",
        "    self.prior_log_neg = -1\n",
        "    \n",
        "    #In how many documents among all Pos corpus/ Neg corpus that we see a word\n",
        "    self.occurrence_count_pos = None\n",
        "    self.occurrence_count_neg = None\n",
        "    \n",
        "    #Log likelihood for each text feature\n",
        "    self.feature_log_likelihood_matrix_pos = None\n",
        "    self.feature_log_likelihood_matrix_neg = None\n",
        "    self.feature_log_likelihood_matrix_not_occurred_pos = None\n",
        "    self.feature_log_likelihood_matrix_not_occurred_neg = None\n",
        "    \n",
        "    #The sum of P(Xi=0|y=1), The sum of P(Xi=0|y=0)\n",
        "    self.sum_feature_log_likelihood_matrix_not_occurred_pos = 0\n",
        "    self.sum_feature_log_likelihood_matrix_not_occurred_neg = 0\n",
        "  \n",
        "  '''Get bag of words in order to calculate binary occurrence'''\n",
        "  def get_BOW(self, X_train):\n",
        "    self.count_vect = CountVectorizer(binary=False).fit(X_train)\n",
        "    X_train_counts = self.count_vect.transform(X_train)\n",
        "    return X_train_counts\n",
        "  \n",
        "  #log(theta)\n",
        "  def log_likelihood_features(self, occurrence_count,y_count, doc_count):\n",
        "    vfunc = np.vectorize(lambda x: math.log(float(x+1)/(y_count+2)))\n",
        "    occurrence_count = vfunc(occurrence_count)\n",
        "    return occurrence_count\n",
        "  \n",
        "  #log(1-theta)\n",
        "  def log_likelihood_features_not_occurred(self, occurrence_count,y_count, doc_count):\n",
        "    vfunc = np.vectorize(lambda x: math.log(1-(float(x+1)/(y_count+2))))\n",
        "    occurrence_count = vfunc(occurrence_count)\n",
        "    return occurrence_count\n",
        "  \n",
        "  def X_train_counts_filter_row(self,y_train_filtered, index_dict, X_train_counts):\n",
        "    return X_train_counts[[index_dict[document_id] for document_id in y_train_filtered.index.values.tolist()]]\n",
        "    \n",
        "  def get_occurrence_count(self):\n",
        "    index_dict = dict(zip(self.y_train.index.values.tolist(), range(self.X_train_counts.shape[0])))\n",
        "    \n",
        "    X_train_counts_pos = self.X_train_counts_filter_row(\n",
        "        self.y_train.loc[y_train == 1],\n",
        "        index_dict,\n",
        "        self.X_train_counts)\n",
        "\n",
        "    X_train_counts_neg = self.X_train_counts_filter_row(\n",
        "        self.y_train.loc[y_train == 0],\n",
        "        index_dict,\n",
        "        self.X_train_counts)\n",
        "    #occurrence_count: the counts of all non-zero entry of each column in the sparse matrix\n",
        "    self.occurrence_count_pos = (X_train_counts_pos != 0).sum(0)\n",
        "    self.occurrence_count_neg = (X_train_counts_neg != 0).sum(0)\n",
        "\n",
        "  def train(self):\n",
        "    self.pos_count =  len(y_train[y_train==1])\n",
        "    self.neg_count = len(y_train[y_train==0])\n",
        "    self.doc_count = self.pos_count + self.neg_count\n",
        "    \n",
        "    self.X_train_counts = self.get_BOW(self.X_train)\n",
        "\n",
        "    self.prior_log_pos = math.log(self.pos_count/self.doc_count)\n",
        "    self.prior_log_neg = math.log(self.neg_count/self.doc_count)\n",
        "\n",
        "    self.get_occurrence_count()\n",
        "    self.feature_log_likelihood_matrix_pos = self.log_likelihood_features(self.occurrence_count_pos,self.pos_count,self.doc_count)\n",
        "    self.feature_log_likelihood_matrix_neg = self.log_likelihood_features(self.occurrence_count_neg,self.neg_count,self.doc_count)\n",
        "\n",
        "    self.feature_log_likelihood_matrix_not_occurred_pos = self.log_likelihood_features_not_occurred(self.occurrence_count_pos,self.pos_count,self.doc_count)\n",
        "    self.feature_log_likelihood_matrix_not_occurred_neg = self.log_likelihood_features_not_occurred(self.occurrence_count_neg,self.neg_count,self.doc_count)\n",
        "\n",
        "    self.sum_feature_log_likelihood_matrix_not_occurred_pos = self.feature_log_likelihood_matrix_not_occurred_pos.sum()\n",
        "    self.sum_feature_log_likelihood_matrix_not_occurred_neg = self.feature_log_likelihood_matrix_not_occurred_neg.sum()\n",
        "\n",
        "  def predict(self,X_test):\n",
        "    y_pred = []\n",
        "    X_test_counts = self.count_vect.transform(X_test)\n",
        "    nrows, ncols = X_test_counts.shape\n",
        "    process = 0\n",
        "    for row in X_test_counts:\n",
        "      likelihood_pos_occur = 0\n",
        "      likelihood_neg_occur = 0\n",
        "      likelihood_pos_not_occur = self.sum_feature_log_likelihood_matrix_not_occurred_pos\n",
        "      likelihood_neg_not_occur = self.sum_feature_log_likelihood_matrix_not_occurred_neg\n",
        "\n",
        "      for ele in row:\n",
        "        for word_index in ele.indices:\n",
        "          likelihood_pos_occur += self.feature_log_likelihood_matrix_pos.item(word_index)\n",
        "          likelihood_neg_occur += self.feature_log_likelihood_matrix_neg.item(word_index)\n",
        "          likelihood_pos_not_occur -= self.feature_log_likelihood_matrix_not_occurred_pos.item(word_index)\n",
        "          likelihood_neg_not_occur -= self.feature_log_likelihood_matrix_not_occurred_neg.item(word_index)\n",
        "\n",
        "      if((likelihood_pos_occur+likelihood_pos_not_occur)\n",
        "         >(likelihood_neg_occur+likelihood_neg_not_occur)): y_pred.append(1)\n",
        "      else: y_pred.append(0)\n",
        "      process += 1\n",
        "      print('\\r %d / %d '%(process,nrows), end='')\n",
        "    return y_pred\n",
        "           \n",
        "    \n",
        "nb_estimator = NaiveBayes(X_train,y_train)\n",
        "nb_estimator.train()\n",
        "y_pred = nb_estimator.predict(X_test)\n",
        "print(\"accuracy on validation set for naive bayes is \", accuracy(y_test, y_pred))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 6250 / 6250 accuracy on validation set for naive bayes is  0.85328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P2t4f-7rG0g6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Output result to csv"
      ]
    },
    {
      "metadata": {
        "id": "sn1ks1_oY_Gl",
        "colab_type": "code",
        "outputId": "55690442-abed-46e7-d912-a3568f7140fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def csv_make(model):\n",
        "  result = df.loc[df['sentiment']>2]\n",
        "  pred = model.predict(result['text'])\n",
        "  \n",
        "  a = {'Id':result['sentiment'], 'Category':pred}\n",
        "  output = pd.DataFrame(data = a)\n",
        "  output = output[['Id', 'Category']]\n",
        "  output['Id'] = output['Id'].map(lambda x:x-100000)\n",
        "  output = output.sort_values(by=['Id'])\n",
        "  csv = output.to_csv(index=False)\n",
        "  f = open('prediction.csv','w')\n",
        "  f.write(csv)\n",
        "  f.close()\n",
        "  return output\n",
        "\n",
        "\n",
        "csv_make(lsvm_cv)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6965</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12063</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17179</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19584</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21023</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7394</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23997</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19247</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10654</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5598</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23128</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12836</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21109</th>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017</th>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3774</th>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5542</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16347</th>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21999</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14049</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10784</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11008</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2858</th>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13040</th>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14554</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>785</th>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14378</th>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8475</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11035</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15623</th>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3560</th>\n",
              "      <td>24970</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20053</th>\n",
              "      <td>24971</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11661</th>\n",
              "      <td>24972</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9732</th>\n",
              "      <td>24973</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8342</th>\n",
              "      <td>24974</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17908</th>\n",
              "      <td>24975</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12035</th>\n",
              "      <td>24976</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13989</th>\n",
              "      <td>24977</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13644</th>\n",
              "      <td>24978</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14443</th>\n",
              "      <td>24979</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13208</th>\n",
              "      <td>24980</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24656</th>\n",
              "      <td>24981</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17436</th>\n",
              "      <td>24982</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13164</th>\n",
              "      <td>24983</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15933</th>\n",
              "      <td>24984</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>24985</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13390</th>\n",
              "      <td>24986</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14627</th>\n",
              "      <td>24987</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20744</th>\n",
              "      <td>24988</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2207</th>\n",
              "      <td>24989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11751</th>\n",
              "      <td>24990</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4380</th>\n",
              "      <td>24991</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22189</th>\n",
              "      <td>24992</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8351</th>\n",
              "      <td>24993</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3348</th>\n",
              "      <td>24994</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23495</th>\n",
              "      <td>24995</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23898</th>\n",
              "      <td>24996</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22972</th>\n",
              "      <td>24997</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24867</th>\n",
              "      <td>24998</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21246</th>\n",
              "      <td>24999</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id  Category\n",
              "6965       0         0\n",
              "12063      1         0\n",
              "17179      2         0\n",
              "19584      3         0\n",
              "21023      4         1\n",
              "7394       5         0\n",
              "23997      6         0\n",
              "824        7         0\n",
              "19247      8         0\n",
              "10654      9         0\n",
              "5598      10         0\n",
              "23128     11         0\n",
              "12836     12         1\n",
              "21109     13         0\n",
              "2017      14         1\n",
              "3774      15         0\n",
              "5542      16         0\n",
              "16347     17         1\n",
              "21999     18         0\n",
              "14049     19         0\n",
              "10784     20         0\n",
              "11008     21         0\n",
              "2858      22         0\n",
              "13040     23         1\n",
              "14554     24         1\n",
              "785       25         1\n",
              "14378     26         0\n",
              "8475      27         0\n",
              "11035     28         0\n",
              "15623     29         1\n",
              "...      ...       ...\n",
              "3560   24970         0\n",
              "20053  24971         0\n",
              "11661  24972         1\n",
              "9732   24973         0\n",
              "8342   24974         1\n",
              "17908  24975         1\n",
              "12035  24976         0\n",
              "13989  24977         1\n",
              "13644  24978         0\n",
              "14443  24979         1\n",
              "13208  24980         1\n",
              "24656  24981         0\n",
              "17436  24982         0\n",
              "13164  24983         1\n",
              "15933  24984         1\n",
              "144    24985         0\n",
              "13390  24986         1\n",
              "14627  24987         0\n",
              "20744  24988         0\n",
              "2207   24989         0\n",
              "11751  24990         1\n",
              "4380   24991         1\n",
              "22189  24992         1\n",
              "8351   24993         0\n",
              "3348   24994         1\n",
              "23495  24995         0\n",
              "23898  24996         1\n",
              "22972  24997         1\n",
              "24867  24998         1\n",
              "21246  24999         1\n",
              "\n",
              "[25000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}